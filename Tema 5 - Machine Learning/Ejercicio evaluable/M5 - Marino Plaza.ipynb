{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preprocesamiento: Se utiliza un ColumnTransformer que aplica una tubería de imputación y escalado a las variables numéricas y una tubería de imputación y codificación OneHot a las categóricas. Esto asegura que todo el preprocesado se realice con scikit-learn.\n",
    "- Clustering: Se usa KMeans sobre las columnas latitude, longitude y price para asignar un cluster a cada registro y luego se visualizan geográficamente.\n",
    "- Selección de características y PCA: Se ejemplifica la selección de las 10 mejores características para la regresión y se aplica PCA para reducir la dimensionalidad a 2 componentes.\n",
    "- Modelado: Se crean dos pipelines, uno para regresión (prediciendo price) y otro para clasificación multiclase (prediciendo room_type), evaluándolos mediante validación cruzada y mostrando métricas.\n",
    "- Visualizaciones: Se incluyen gráficos para EDA y para la comparación de tiempos y métricas durante la validación cruzada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga y preprocesado inicial:\n",
    "\n",
    "Se eliminan las columnas id, host_id y host_name.\n",
    "Se transforma la columna de fecha (en este caso, se utiliza last_review) a tipo datetime y se descompone en columnas de año, mes y día.\n",
    "Análisis Exploratorio de Datos (EDA):\n",
    "\n",
    "Se realizan gráficos univariantes (histograma, boxplot para price y countplot para room_type).\n",
    "Se incluye un gráfico bivariante (scatterplot de price vs. minimum_nights).\n",
    "Se generan gráficos multivariantes (heatmap de correlaciones y pairplot con variables numéricas seleccionadas).\n",
    "Preprocesamiento usando Scikit-Learn:\n",
    "\n",
    "Se crean pipelines separados para variables numéricas (con imputación y escalado) y categóricas (con imputación y OneHotEncoding).\n",
    "Todo el preprocesado se realiza con scikit-learn, cumpliendo el requisito de no usar métodos propios de pandas para estos pasos.\n",
    "Clustering:\n",
    "\n",
    "Se aplica KMeans para generar una columna cluster (usando las variables latitude, longitude y price).\n",
    "Se utiliza dicha columna para colorear un scatterplot geográfico, lo que facilita el análisis visual de los grupos.\n",
    "Selección de características y reducción de dimensionalidad:\n",
    "\n",
    "Se usa SelectKBest para filtrar las mejores variables en el contexto de la regresión.\n",
    "Se aplica PCA para reducir la dimensionalidad a dos componentes, lo cual es útil para visualización o análisis posterior.\n",
    "Modelado:\n",
    "\n",
    "Regresión: Se crea un pipeline que incluye el preprocesado y un modelo de regresión lineal para predecir la columna price.\n",
    "Clasificación Multiclase: Se construye un pipeline similar que utiliza LogisticRegression para predecir la columna room_type.\n",
    "Validación Cruzada y Comparación de Resultados:\n",
    "\n",
    "Se realizan validaciones cruzadas para ambos modelos (regresión y clasificación) y se muestran los resultados en dataframes con las métricas calculadas.\n",
    "Además, se incluyen gráficos (boxplots) opcionales que muestran los tiempos de ejecución y las métricas obtenidas en la validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ejercicio completo:\n",
    "  - Carga y preprocesado del dataset de Airbnb NYC\n",
    "  - Análisis exploratorio de datos (EDA): univariado, bivariado y multivariado\n",
    "  - Preprocesamiento usando scikit-learn (imputación, escalado y codificación)\n",
    "  - Clustering con KMeans y visualización\n",
    "  - Selección de características con SelectKBest y reducción de dimensionalidad con PCA\n",
    "  - Modelado de regresión para predecir 'price'\n",
    "  - Modelado de clasificación multiclase para predecir 'room_type'\n",
    "  - Evaluación de modelos con validación cruzada y resumen de métricas\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Librerías y carga de datos\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score\n",
    "import time\n",
    "\n",
    "# Cargar el dataset (asegúrate de que el archivo se encuentre en el directorio actual)\n",
    "df = pd.read_csv('AB_NYC_2019.csv')\n",
    "print(\"Dimensión original del dataset:\", df.shape)\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Preprocesado inicial: eliminación de columnas y manejo de fecha\n",
    "# =============================================================================\n",
    "# Quitar columnas: 'id', 'host_id', 'host_name'\n",
    "df.drop(['id', 'host_id', 'host_name'], axis=1, inplace=True)\n",
    "\n",
    "# Revisar columnas para identificar la columna de fecha; en este dataset se usa \"last_review\"\n",
    "# Convertir \"last_review\" a datetime y descomponer en año, mes y día\n",
    "df['last_review'] = pd.to_datetime(df['last_review'], errors='coerce')\n",
    "df['last_review_year']  = df['last_review'].dt.year\n",
    "df['last_review_month'] = df['last_review'].dt.month\n",
    "df['last_review_day']   = df['last_review'].dt.day\n",
    "\n",
    "# Opcional: Si no se desea conservar la columna original de fecha, se puede eliminar\n",
    "# df.drop('last_review', axis=1, inplace=True)\n",
    "\n",
    "print(\"Columnas luego del preprocesado inicial:\", df.columns.tolist())\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Análisis Exploratorio de Datos (EDA)\n",
    "# =============================================================================\n",
    "# --- EDA Univariado ---\n",
    "# Histograma de 'price'\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(df['price'].dropna(), bins=30, kde=True)\n",
    "plt.title(\"Histograma de Price\")\n",
    "plt.xlabel(\"Price\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.show()\n",
    "\n",
    "# Boxplot de 'price'\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(x=df['price'])\n",
    "plt.title(\"Boxplot de Price\")\n",
    "plt.xlabel(\"Price\")\n",
    "plt.show()\n",
    "\n",
    "# Countplot de la variable categórica 'room_type'\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='room_type', data=df)\n",
    "plt.title(\"Conteo de Room Type\")\n",
    "plt.xlabel(\"Room Type\")\n",
    "plt.ylabel(\"Conteo\")\n",
    "plt.show()\n",
    "\n",
    "# --- EDA Bivariado ---\n",
    "# Scatterplot: price vs. minimum_nights\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='minimum_nights', y='price', data=df, alpha=0.5)\n",
    "plt.title(\"Scatterplot: Price vs Minimum Nights\")\n",
    "plt.xlabel(\"Minimum Nights\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.show()\n",
    "\n",
    "# --- EDA Multivariado ---\n",
    "# Matriz de correlación (solo variables numéricas)\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr = df.select_dtypes(include=[np.number]).corr()\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Heatmap de Correlaciones\")\n",
    "plt.show()\n",
    "\n",
    "# Pairplot (usando algunas variables numéricas de interés)\n",
    "cols_pairplot = ['price', 'minimum_nights', 'number_of_reviews', 'availability_365']\n",
    "sns.pairplot(df[cols_pairplot].dropna())\n",
    "plt.suptitle(\"Pairplot de variables numéricas\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Preprocesamiento con scikit-learn: Imputación, Escalado y Codificación\n",
    "# =============================================================================\n",
    "# Identificar variables numéricas y categóricas\n",
    "num_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "# Excluir la variable target en cada caso (aquí se mantienen para la transformación general)\n",
    "cat_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"Variables numéricas para preprocesamiento:\", num_features)\n",
    "print(\"Variables categóricas para preprocesamiento:\", cat_features)\n",
    "\n",
    "# Pipeline para variables numéricas\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline para variables categóricas\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# ColumnTransformer que aplica las transformaciones a cada tipo de variable\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_pipeline, num_features),\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "])\n",
    "\n",
    "# Ejemplo de transformación (se podría aplicar luego a X en modelado)\n",
    "X_transformed = preprocessor.fit_transform(df)\n",
    "print(\"Forma de la matriz transformada:\", X_transformed.shape)\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Clustering y visualización con Siluetas\n",
    "# =============================================================================\n",
    "# Seleccionar características para clustering (por ejemplo: latitud, longitud y precio)\n",
    "clust_features = ['latitude', 'longitude', 'price']\n",
    "# En caso de valores faltantes en estas columnas, se pueden imputar con 0 o de otra manera\n",
    "df_clust = df[clust_features].fillna(0)\n",
    "\n",
    "# Pipeline: escalado y clustering con KMeans (n_clusters=3)\n",
    "cluster_pipeline = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('kmeans', KMeans(n_clusters=3, random_state=42))\n",
    "])\n",
    "\n",
    "# Ajustar el modelo y asignar etiquetas de cluster\n",
    "df['cluster'] = cluster_pipeline.fit_predict(df_clust)\n",
    "print(\"Conteo de clusters:\\n\", df['cluster'].value_counts())\n",
    "\n",
    "# Visualización: scatterplot de latitud vs. longitud coloreado por cluster\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='longitude', y='latitude', hue='cluster', data=df, palette='Set1', alpha=0.6)\n",
    "plt.title(\"Clusters geográficos (KMeans)\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 6. Feature Selection: SelectKBest y PCA (Ejemplo con regresión)\n",
    "# =============================================================================\n",
    "# Para la regresión se predecirá 'price'\n",
    "# Separar X (todas las variables excepto 'price' y 'room_type') y y (target)\n",
    "X_reg = df.drop(['price', 'room_type'], axis=1)\n",
    "y_reg = df['price']\n",
    "\n",
    "# Aplicar preprocesamiento a X_reg (la transformación de variables numéricas y categóricas)\n",
    "X_reg_transformed = preprocessor.fit_transform(X_reg)\n",
    "print(\"Forma de X para regresión luego de preprocesamiento:\", X_reg_transformed.shape)\n",
    "\n",
    "# Selección de características con SelectKBest (usando f_regression) para elegir las 10 mejores\n",
    "selector = SelectKBest(score_func=f_regression, k=10)\n",
    "X_reg_selected = selector.fit_transform(X_reg_transformed, y_reg)\n",
    "print(\"Forma de X luego de SelectKBest:\", X_reg_selected.shape)\n",
    "\n",
    "# Aplicar PCA para reducción de dimensionalidad a 2 componentes (para visualización o análisis posterior)\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_reg_pca = pca.fit_transform(X_reg_transformed)\n",
    "print(\"Forma de X luego de PCA:\", X_reg_pca.shape)\n",
    "\n",
    "# =============================================================================\n",
    "# 7. Regresión: Predecir la columna 'price'\n",
    "# =============================================================================\n",
    "# Se crea un pipeline que incluye el preprocesador y el modelo de regresión (LinearRegression)\n",
    "reg_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Usar validación cruzada para evaluar el modelo\n",
    "# Se utilizan 5 folds y se calculan MSE y MAE (scoring negativo por convención en sklearn)\n",
    "cv_results_reg = cross_validate(\n",
    "    reg_pipeline,\n",
    "    X_reg, y_reg,\n",
    "    cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring={'MSE': 'neg_mean_squared_error', 'MAE': 'neg_mean_absolute_error'},\n",
    "    return_train_score=True,\n",
    "    return_estimator=False,\n",
    "    return_times=True\n",
    ")\n",
    "\n",
    "# Mostrar resultados promedio y desviación estándar\n",
    "print(\"\\n=== Resultados Regresión (LinearRegression) ===\")\n",
    "print(\"MSE (negativo): {:.3f} ± {:.3f}\".format(\n",
    "    np.mean(cv_results_reg['test_MSE']),\n",
    "    np.std(cv_results_reg['test_MSE'])\n",
    "))\n",
    "print(\"MAE (negativo): {:.3f} ± {:.3f}\".format(\n",
    "    np.mean(cv_results_reg['test_MAE']),\n",
    "    np.std(cv_results_reg['test_MAE'])\n",
    "))\n",
    "\n",
    "# =============================================================================\n",
    "# 8. Clasificación Multiclase: Predecir la columna 'room_type'\n",
    "# =============================================================================\n",
    "# Separar X (todas las variables excepto 'price' y 'room_type') y y (target)\n",
    "X_clf = df.drop(['price', 'room_type'], axis=1)\n",
    "y_clf = df['room_type']\n",
    "\n",
    "# Pipeline para clasificación: se usa el mismo preprocesador y LogisticRegression\n",
    "clf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs', random_state=42))\n",
    "])\n",
    "\n",
    "# Evaluación con validación cruzada (5 folds), usando la métrica de exactitud (accuracy)\n",
    "cv_results_clf = cross_validate(\n",
    "    clf_pipeline,\n",
    "    X_clf, y_clf,\n",
    "    cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring={'accuracy': 'accuracy'},\n",
    "    return_train_score=True,\n",
    "    return_times=True\n",
    ")\n",
    "\n",
    "print(\"\\n=== Resultados Clasificación (LogisticRegression) ===\")\n",
    "print(\"Accuracy (train): {:.3f} ± {:.3f}\".format(\n",
    "    np.mean(cv_results_clf['train_accuracy']),\n",
    "    np.std(cv_results_clf['train_accuracy'])\n",
    "))\n",
    "print(\"Accuracy (test): {:.3f} ± {:.3f}\".format(\n",
    "    np.mean(cv_results_clf['test_accuracy']),\n",
    "    np.std(cv_results_clf['test_accuracy'])\n",
    "))\n",
    "\n",
    "# =============================================================================\n",
    "# 9. Comparación de Resultados con Validación Cruzada\n",
    "# =============================================================================\n",
    "# Crear un DataFrame resumen para regresión\n",
    "df_results_reg = pd.DataFrame({\n",
    "    'MSE_train': cv_results_reg['train_MSE'],\n",
    "    'MSE_test': cv_results_reg['test_MSE'],\n",
    "    'MAE_train': cv_results_reg['train_MAE'],\n",
    "    'MAE_test': cv_results_reg['test_MAE'],\n",
    "    'fit_time': cv_results_reg['fit_time'],\n",
    "    'score_time': cv_results_reg['score_time']\n",
    "})\n",
    "print(\"\\n=== Resultados de Regresión por Fold ===\")\n",
    "print(df_results_reg)\n",
    "\n",
    "# Crear un DataFrame resumen para clasificación\n",
    "df_results_clf = pd.DataFrame({\n",
    "    'accuracy_train': cv_results_clf['train_accuracy'],\n",
    "    'accuracy_test': cv_results_clf['test_accuracy'],\n",
    "    'fit_time': cv_results_clf['fit_time'],\n",
    "    'score_time': cv_results_clf['score_time']\n",
    "})\n",
    "print(\"\\n=== Resultados de Clasificación por Fold ===\")\n",
    "print(df_results_clf)\n",
    "\n",
    "# Opcional: Boxplots para tiempos de ejecución y métricas (ejemplo para regresión)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(data=df_results_reg[['fit_time', 'score_time']])\n",
    "plt.title(\"Tiempos de ejecución (Regresión)\")\n",
    "plt.ylabel(\"Tiempo (segundos)\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Convertir métricas negativas a positivas para facilitar la interpretación\n",
    "sns.boxplot(data=pd.DataFrame({\n",
    "    'MSE_test': -df_results_reg['MSE_test'],\n",
    "    'MAE_test': -df_results_reg['MAE_test']\n",
    "}))\n",
    "plt.title(\"Métricas (Regresión)\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "print('numerical_cols', numerical_cols)\n",
    "pipeline_numerical = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "categorical_cols = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "print('categorical_cols', numerical_cols)\n",
    "pipeline_categorical = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='others')),\n",
    "   # ('encoder', OrdinalEncoder()),\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "pipeline_all = ColumnTransformer([\n",
    "    ('numeric', pipeline_numerical, numerical_cols),\n",
    "    ('categorical', pipeline_categorical, categorical_cols)\n",
    "])\n",
    "pipeline = make_pipeline(\n",
    "    pipeline_all,\n",
    "    LinearRegression()\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "r2_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
