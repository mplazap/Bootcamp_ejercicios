{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uso de PipeLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('pipeline_penguins').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------+-------------+-----------------+-----------+------+\n",
      "|species|   island|bill_length_mm|bill_depth_mm|flipper_length_mm|body_mass_g|   sex|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+\n",
      "| Adelie|Torgersen|          39.1|         18.7|            181.0|       3750|  MALE|\n",
      "| Adelie|Torgersen|          39.5|         17.4|            186.0|       3800|FEMALE|\n",
      "| Adelie|Torgersen|          40.3|         18.0|            195.0|       3250|FEMALE|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+\n",
      "only showing top 3 rows\n",
      "\n",
      "root\n",
      " |-- species: string (nullable = true)\n",
      " |-- island: string (nullable = true)\n",
      " |-- bill_length_mm: float (nullable = true)\n",
      " |-- bill_depth_mm: float (nullable = true)\n",
      " |-- flipper_length_mm: float (nullable = true)\n",
      " |-- body_mass_g: integer (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pyspark.sql.types import StructType, StructField, FloatType, StringType, IntegerType\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/refs/heads/master/penguins.csv'\n",
    "csv_path = 'penguins.csv'\n",
    "\n",
    "with open(csv_path, 'wb') as file:\n",
    "    file.write(requests.get(url).content)\n",
    "    \n",
    "schema = StructType([\n",
    "    StructField('species', StringType(), True),\n",
    "    StructField('island', StringType(), True),\n",
    "    StructField('bill_length_mm', FloatType(), True),\n",
    "    StructField('bill_depth_mm', FloatType(), True),\n",
    "    StructField('flipper_length_mm', FloatType(), True),\n",
    "    StructField('body_mass_g', IntegerType(), True),\n",
    "    StructField('sex', StringType(), True),\n",
    "])\n",
    "\n",
    "df = spark.read.csv(csv_path, header=True, inferSchema=False, schema=schema)\n",
    "df.show(3)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+--------------+-------------+-----------------+-----------+---+\n",
      "|species|island|bill_length_mm|bill_depth_mm|flipper_length_mm|body_mass_g|sex|\n",
      "+-------+------+--------------+-------------+-----------------+-----------+---+\n",
      "|      0|     0|             2|            2|                2|          2| 11|\n",
      "+-------+------+--------------+-------------+-----------------+-----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum \n",
    "\n",
    "# Columna a predecir\n",
    "# Borramos filas donde 'ìsland' sea nan\n",
    "df = df.dropna(subset=['island'])\n",
    "\n",
    "# contar nulos (equivalente a df.isna().sum() en Pandas)\n",
    "df.select([sum(col(c).isNull().cast('int')).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocesados para hacer despues el pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
      "['species', 'sex']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import NumericType, StringType\n",
    "\n",
    "# Selecionamos las columnas a las que aplicar preprocesados\n",
    "numerical_cols = [field.name for field in df.schema.fields if isinstance(field.dataType, NumericType)]\n",
    "# Filtramos island porque island es la variable a predecir y ya hemos asegurado que no tiene nan\n",
    "categorical_cols = [field.name for field in df.schema.fields if isinstance(field.dataType, StringType) and field.name != 'island']\n",
    "label_col = 'island'\n",
    "\n",
    "print(numerical_cols)\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexer para la columna 'island', que es la columna a predecir\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, Imputer, OneHotEncoder, VectorAssembler\n",
    "\n",
    "indexer_label = StringIndexer(\n",
    "    inputCol=label_col,\n",
    "    outputCol='label',\n",
    "    handleInvalid='keep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['species_indexed', 'sex_indexed']\n"
     ]
    }
   ],
   "source": [
    "# Indexer para las features(columnas) de la entrada que no son la columna 'label' que es la que se va apredecir\n",
    "# Al hacer el Indexer las transformamos a numericas (0,1,2,etc)\n",
    "# crea un objeto StringIndexer por cada columna categórica a indexar\n",
    "\n",
    "indexers_features = [\n",
    "    StringIndexer(inputCol=c, outputCol=c + '_indexed', handleInvalid='keep') for c in categorical_cols\n",
    "]\n",
    "categorical_cols_indexed = [c + '_indexed' for c in categorical_cols]\n",
    "print(categorical_cols_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['species_indexed_imputed', 'sex_indexed_imputed']\n"
     ]
    }
   ],
   "source": [
    "# Imputer con la moda a las columnas categoricas indexadas\n",
    "# Al hacer el imputer rellenamos las columnas nuevas creadas\n",
    "\n",
    "imputer_categorical = Imputer(\n",
    "    inputCols=categorical_cols_indexed,\n",
    "    outputCols=[c + '_imputed' for c in categorical_cols_indexed],\n",
    "    strategy='mode'\n",
    ")\n",
    "categorical_cols_indexed_imputed = [c + '_imputed' for c in categorical_cols_indexed]\n",
    "print(categorical_cols_indexed_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['species_indexed_imputed_onehot', 'sex_indexed_imputed_onehot']\n"
     ]
    }
   ],
   "source": [
    "# one hot encoders para las categóricas indexadas imputadas\n",
    "encoders_onehot = [\n",
    "    OneHotEncoder(inputCol=c, outputCol=c + '_onehot') \n",
    "    for c in categorical_cols_indexed_imputed\n",
    "]\n",
    "categorical_cols_onehot = [c + '_onehot' for c in categorical_cols_indexed_imputed]\n",
    "print(categorical_cols_onehot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bill_length_mm_imputed', 'bill_depth_mm_imputed', 'flipper_length_mm_imputed', 'body_mass_g_imputed']\n"
     ]
    }
   ],
   "source": [
    "# Imputer con la mediana para la columnas numéricas\n",
    "imputer_numerical = Imputer(\n",
    "    inputCols=numerical_cols,\n",
    "    outputCols=[c + '_imputed' for c in numerical_cols],\n",
    "    strategy='median'\n",
    ")\n",
    "numerical_cols_imputed = [c + '_imputed' for c in numerical_cols]\n",
    "print(numerical_cols_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "# (Opcional) escalar numéricas con MinMaxScaler\n",
    "assembler_numerical = VectorAssembler(\n",
    "    inputCols=numerical_cols_imputed,\n",
    "    outputCol='numeric_features'\n",
    ")\n",
    "scaler = MinMaxScaler(\n",
    "    inputCol='numeric_features',\n",
    "    outputCol='numeric_features_scaled'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['numeric_features_scaled', 'species_indexed_imputed_onehot', 'sex_indexed_imputed_onehot']\n"
     ]
    }
   ],
   "source": [
    "all_columns = ['numeric_features_scaled'] + categorical_cols_onehot\n",
    "print(all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensamblar todo: numéricas + categóricas y obtener features\n",
    "assembler_all = VectorAssembler(\n",
    "    inputCols=all_columns,\n",
    "    outputCol='features'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# particionamiento de datos\n",
    "df_train, df_test = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages = [\n",
    "    # 1. Indexer para columna categórica 'island' StringIndexer porque es la columna a predecir\n",
    "    indexer_label,\n",
    "    # 2. Indexers para columnas categóricas: 'species', 'sex' \n",
    "    *indexers_features, # ponemos * porque es una lista de objetos\n",
    "    # 3. Imputer para categóricas\n",
    "    imputer_categorical,\n",
    "    # 4. One Hot Encoders para categóricas\n",
    "    *encoders_onehot, # ponemos * porque es una lista de objetos\n",
    "    # 5. Imputer para numéricas\n",
    "    imputer_numerical,\n",
    "    # 6. Ensamblar numéricas + escalado\n",
    "    assembler_numerical,\n",
    "    scaler,\n",
    "    # 7. Ensamblar numéricas escaladas + categóricas en una sola columna 'features'\n",
    "    assembler_all,\n",
    "    # 8. modelo de clasificación\n",
    "    classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = pipeline.fit(df_train)\n",
    "df_pred = pipeline_model.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
