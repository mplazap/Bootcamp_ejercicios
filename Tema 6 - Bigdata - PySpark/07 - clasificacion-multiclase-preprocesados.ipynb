{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------+-------------+-----------------+-----------+------+\n",
      "|species|   island|bill_length_mm|bill_depth_mm|flipper_length_mm|body_mass_g|   sex|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+\n",
      "| Adelie|Torgersen|          39.1|         18.7|            181.0|     3750.0|  Male|\n",
      "| Adelie|Torgersen|          39.5|         17.4|            186.0|     3800.0|Female|\n",
      "| Adelie|Torgersen|          40.3|         18.0|            195.0|     3250.0|Female|\n",
      "| Adelie|Torgersen|           NaN|          NaN|              NaN|        NaN|   NaN|\n",
      "| Adelie|Torgersen|          36.7|         19.3|            193.0|     3450.0|Female|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('clasificacion_penguins').getOrCreate()\n",
    "df = spark.createDataFrame(sns.load_dataset('penguins'))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queremos predecir species por tanto elimino filas donde species sea nan\n",
    "df = df.dropna(subset=['species'])\n",
    "# si estuviera en dataframe de pandas: \n",
    "# df['island'] = df['island'].fillna('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
      "['island', 'sex']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import NumericType, StringType\n",
    "\n",
    "numeric_cols = [field.name for field in df.schema.fields if isinstance(field.dataType, NumericType)]\n",
    "# Filtramos species porque species es la variable a predecir y ya hemos asegurado que no tiene nan\n",
    "categorical_cols = [field.name for field in df.schema.fields if isinstance(field.dataType, StringType) and field.name != 'species']\n",
    "\n",
    "print(numeric_cols)\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+\n",
      "|species|   island|bill_length_mm|bill_depth_mm|flipper_length_mm|body_mass_g|   sex|bill_length_mm_imputed|bill_depth_mm_imputed|flipper_length_mm_imputed|body_mass_g_imputed|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+\n",
      "| Adelie|   Biscoe|          37.8|         18.3|            174.0|     3400.0|Female|                  37.8|                 18.3|                    174.0|             3400.0|\n",
      "| Adelie|Torgersen|          34.1|         18.1|            193.0|     3475.0|   NaN|                  34.1|                 18.1|                    193.0|             3475.0|\n",
      "| Adelie|Torgersen|          34.6|         21.1|            198.0|     4400.0|  Male|                  34.6|                 21.1|                    198.0|             4400.0|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    strategy='median',\n",
    "    inputCols=numeric_cols,\n",
    "    outputCols=[col + '_imputed' for col in numeric_cols]\n",
    ")\n",
    "imputer_model = imputer.fit(df_train) # fit solo sobre train para evitar fuga de datos data leakage\n",
    "df_train = imputer_model.transform(df_train)\n",
    "df_test = imputer_model.transform(df_test)\n",
    "df_train.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- species: string (nullable = true)\n",
      " |-- island: string (nullable = true)\n",
      " |-- bill_length_mm: double (nullable = true)\n",
      " |-- bill_depth_mm: double (nullable = true)\n",
      " |-- flipper_length_mm: double (nullable = true)\n",
      " |-- body_mass_g: double (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- bill_length_mm_imputed: double (nullable = true)\n",
      " |-- bill_depth_mm_imputed: double (nullable = true)\n",
      " |-- flipper_length_mm_imputed: double (nullable = true)\n",
      " |-- body_mass_g_imputed: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opción 1: rellenar con un valor fijo\n",
    "# al inferir el schema automáticamente nos está diciendo que la columna sex NO es nullable y no tiene nan, por lo que en realidad\n",
    "# lo que está pasando es que los NaN los tiene como palabras 'NaN' texto, por tanto no sirve el fill y usamos replace:\n",
    "\n",
    "# df_train = df_train.na.fill('other', subset=categorical_cols)\n",
    "# df_test = df_test.na.fill('other', subset=categorical_cols)\n",
    "\n",
    "# df_train = df_train.fillna('other', subset=categorical_cols)\n",
    "# df_test = df_test.fillna('other', subset=categorical_cols)\n",
    "\n",
    "# df_train = df_train.replace('NaN', 'other', subset=categorical_cols)\n",
    "# df_test = df_test.replace('NaN', 'other', subset=categorical_cols)\n",
    "\n",
    "# df_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opción 2: usar Imputer\n",
    "# No se puede, IllegalArgumentException, requiere numéricas.\n",
    "# Se haría si hemos hecho primero un StringIndexer para convertir a numéricas a índices\n",
    "# imputer = Imputer(\n",
    "#     strategy='mode',\n",
    "#     inputCols=categorical_cols,\n",
    "#     outputCols=[col + '_imputed' for col in categorical_cols]\n",
    "# )\n",
    "# imputer_model = imputer.fit(df_train) # fit solo sobre train para evitar fuga de datos data leakage\n",
    "# df_train = imputer_model.transform(df_train)\n",
    "# df_test = imputer_model.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|   island|count|\n",
      "+---------+-----+\n",
      "|   Biscoe|  168|\n",
      "|    Dream|  124|\n",
      "|Torgersen|   52|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ver value_counts para ver valors más frecuentes\n",
    "from pyspark.sql.functions import col\n",
    "df.groupBy('island').count().orderBy(col('count').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   sex|count|\n",
      "+------+-----+\n",
      "|  Male|  168|\n",
      "|Female|  165|\n",
      "|   NaN|   11|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('sex').count().orderBy(col('count').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+\n",
      "|species|   island|bill_length_mm|bill_depth_mm|flipper_length_mm|body_mass_g|   sex|bill_length_mm_imputed|bill_depth_mm_imputed|flipper_length_mm_imputed|body_mass_g_imputed|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+\n",
      "| Adelie|   Biscoe|          37.8|         18.3|            174.0|     3400.0|Female|                  37.8|                 18.3|                    174.0|             3400.0|\n",
      "| Adelie|Torgersen|          34.1|         18.1|            193.0|     3475.0|  Male|                  34.1|                 18.1|                    193.0|             3475.0|\n",
      "| Adelie|Torgersen|          34.6|         21.1|            198.0|     4400.0|  Male|                  34.6|                 21.1|                    198.0|             4400.0|\n",
      "| Adelie|Torgersen|          36.6|         17.8|            185.0|     3700.0|Female|                  36.6|                 17.8|                    185.0|             3700.0|\n",
      "| Adelie|Torgersen|          36.7|         19.3|            193.0|     3450.0|Female|                  36.7|                 19.3|                    193.0|             3450.0|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Opción 3: rellenar con la moda\n",
    "island_mode = df.groupBy('island').count().orderBy(col('count').desc()).first()['island']\n",
    "sex_mode = df.groupBy('sex').count().orderBy(col('count').desc()).first()['sex']\n",
    "\n",
    "df_train = df_train.replace('NaN', island_mode, subset=['island'])\n",
    "df_test = df_test.replace('NaN', island_mode, subset=['island'])\n",
    "\n",
    "df_train = df_train.replace('NaN', sex_mode, subset=['sex'])\n",
    "df_test = df_test.replace('NaN', sex_mode, subset=['sex'])\n",
    "\n",
    "df_train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StringIndexer + OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+\n",
      "|species|   island|bill_length_mm|bill_depth_mm|flipper_length_mm|body_mass_g|   sex|bill_length_mm_imputed|bill_depth_mm_imputed|flipper_length_mm_imputed|body_mass_g_imputed|label|island_indexed|sex_indexed|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+\n",
      "| Adelie|   Biscoe|          37.8|         18.3|            174.0|     3400.0|Female|                  37.8|                 18.3|                    174.0|             3400.0|  0.0|           0.0|        1.0|\n",
      "| Adelie|Torgersen|          34.1|         18.1|            193.0|     3475.0|  Male|                  34.1|                 18.1|                    193.0|             3475.0|  0.0|           2.0|        0.0|\n",
      "| Adelie|Torgersen|          34.6|         21.1|            198.0|     4400.0|  Male|                  34.6|                 21.1|                    198.0|             4400.0|  0.0|           2.0|        0.0|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Indexar 'species' columna a predecir. Ya no le aplicamos OneHotEncoder\n",
    "indexer_label = StringIndexer(inputCol='species', outputCol='label')\n",
    "indexer_model = indexer_label.fit(df_train)\n",
    "df_train = indexer_model.transform(df_train)\n",
    "df_test = indexer_model.transform(df_test)\n",
    "\n",
    "# indexar las otras categóricas\n",
    "for categorical_col in categorical_cols:\n",
    "    indexer = StringIndexer(inputCol=categorical_col, outputCol=categorical_col + '_indexed')\n",
    "    model = indexer.fit(df_train)\n",
    "    df_train = model.transform(df_train)\n",
    "    df_test = model.transform(df_test)\n",
    "    \n",
    "df_train.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+-------------+-------------+\n",
      "|species|   island|bill_length_mm|bill_depth_mm|flipper_length_mm|body_mass_g|   sex|bill_length_mm_imputed|bill_depth_mm_imputed|flipper_length_mm_imputed|body_mass_g_imputed|label|island_indexed|sex_indexed|island_onehot|   sex_onehot|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+-------------+-------------+\n",
      "| Adelie|   Biscoe|          37.8|         18.3|            174.0|     3400.0|Female|                  37.8|                 18.3|                    174.0|             3400.0|  0.0|           0.0|        1.0|(2,[0],[1.0])|    (1,[],[])|\n",
      "| Adelie|Torgersen|          34.1|         18.1|            193.0|     3475.0|  Male|                  34.1|                 18.1|                    193.0|             3475.0|  0.0|           2.0|        0.0|    (2,[],[])|(1,[0],[1.0])|\n",
      "| Adelie|Torgersen|          34.6|         21.1|            198.0|     4400.0|  Male|                  34.6|                 21.1|                    198.0|             4400.0|  0.0|           2.0|        0.0|    (2,[],[])|(1,[0],[1.0])|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+-------------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[col + '_indexed' for col in categorical_cols], # añadimos sufijo + '_indexed' para que solo lea las indexadas y no las texto\n",
    "    outputCols=[col + '_onehot' for col in categorical_cols] # se generan nuevas columnas  con sufijo _onehot\n",
    ")\n",
    "model = encoder.fit(df_train)\n",
    "df_train = model.transform(df_train)\n",
    "df_test = model.transform(df_test)\n",
    "\n",
    "df_train.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['island_onehot',\n",
       " 'sex_onehot',\n",
       " 'bill_length_mm_imputed',\n",
       " 'bill_depth_mm_imputed',\n",
       " 'flipper_length_mm_imputed',\n",
       " 'body_mass_g_imputed']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot = [col + '_onehot' for col in categorical_cols]\n",
    "imputed = [col + '_imputed' for col in numeric_cols]\n",
    "onehot + imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+-------------+-------------+--------------------+\n",
      "|species|   island|bill_length_mm|bill_depth_mm|flipper_length_mm|body_mass_g|   sex|bill_length_mm_imputed|bill_depth_mm_imputed|flipper_length_mm_imputed|body_mass_g_imputed|label|island_indexed|sex_indexed|island_onehot|   sex_onehot|            features|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+-------------+-------------+--------------------+\n",
      "| Adelie|   Biscoe|          37.8|         18.3|            174.0|     3400.0|Female|                  37.8|                 18.3|                    174.0|             3400.0|  0.0|           0.0|        1.0|(2,[0],[1.0])|    (1,[],[])|[1.0,0.0,0.0,37.8...|\n",
      "| Adelie|Torgersen|          34.1|         18.1|            193.0|     3475.0|  Male|                  34.1|                 18.1|                    193.0|             3475.0|  0.0|           2.0|        0.0|    (2,[],[])|(1,[0],[1.0])|[0.0,0.0,1.0,34.1...|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+-------------+-------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=onehot + imputed,\n",
    "    outputCol='features'\n",
    ")\n",
    "df_train = assembler.transform(df_train)\n",
    "df_test = assembler.transform(df_test)\n",
    "\n",
    "df_train.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+-------------+-------------+--------------------+--------------------+\n",
      "|species|   island|bill_length_mm|bill_depth_mm|flipper_length_mm|body_mass_g|   sex|bill_length_mm_imputed|bill_depth_mm_imputed|flipper_length_mm_imputed|body_mass_g_imputed|label|island_indexed|sex_indexed|island_onehot|   sex_onehot|            features|     scaled_features|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+-------------+-------------+--------------------+--------------------+\n",
      "| Adelie|   Biscoe|          37.8|         18.3|            174.0|     3400.0|Female|                  37.8|                 18.3|                    174.0|             3400.0|  0.0|           0.0|        1.0|(2,[0],[1.0])|    (1,[],[])|[1.0,0.0,0.0,37.8...|[1.04164657191019...|\n",
      "| Adelie|Torgersen|          34.1|         18.1|            193.0|     3475.0|  Male|                  34.1|                 18.1|                    193.0|             3475.0|  0.0|           2.0|        0.0|    (2,[],[])|(1,[0],[1.0])|[0.0,0.0,1.0,34.1...|[-0.9566141986930...|\n",
      "| Adelie|Torgersen|          34.6|         21.1|            198.0|     4400.0|  Male|                  34.6|                 21.1|                    198.0|             4400.0|  0.0|           2.0|        0.0|    (2,[],[])|(1,[0],[1.0])|[0.0,0.0,1.0,34.6...|[-0.9566141986930...|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+-------------+-------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(\n",
    "    inputCol='features',\n",
    "    outputCol='scaled_features',\n",
    "    withMean=True # centrar\n",
    ")\n",
    "model = scaler.fit(df_train)\n",
    "df_train = model.transform(df_train)\n",
    "df_test = model.transform(df_test)\n",
    "\n",
    "df_train.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_accuracy = MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(metricName='f1')\n",
    "evaluator_precision = MulticlassClassificationEvaluator(metricName='weightedPrecision')\n",
    "evaluator_recall = MulticlassClassificationEvaluator(metricName='weightedRecall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1.0\n",
      "f1 1.0\n",
      "precision 1.0\n",
      "recall 1.0\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression() # por defecto usa 'features' que están sin estandarizar/escalar\n",
    "model = lr.fit(df_train)\n",
    "df_pred = model.transform(df_test)\n",
    "print('accuracy', evaluator_accuracy.evaluate(df_pred))\n",
    "print('f1', evaluator_f1.evaluate(df_pred))\n",
    "print('precision', evaluator_precision.evaluate(df_pred))\n",
    "print('recall', evaluator_recall.evaluate(df_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1.0\n",
      "f1 1.0\n",
      "precision 1.0\n",
      "recall 1.0\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(featuresCol='scaled_features')\n",
    "model = lr.fit(df_train)\n",
    "df_pred = model.transform(df_test)\n",
    "print('accuracy', evaluator_accuracy.evaluate(df_pred))\n",
    "print('f1', evaluator_f1.evaluate(df_pred))\n",
    "print('precision', evaluator_precision.evaluate(df_pred))\n",
    "print('recall', evaluator_recall.evaluate(df_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
